import streamlit as st
import pandas as pd
import time
import gspread
import json
import re
import pytz
import uuid
import numpy as np
import gc
from gspread_dataframe import set_with_dataframe, get_as_dataframe
from datetime import datetime
from google.oauth2 import service_account
from collections import defaultdict
from st_copy_to_clipboard import st_copy_to_clipboard

# ==========================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==========================================
st.set_page_config(page_title="Kinkin Tool 2.0", layout="wide", page_icon="üíé")

AUTHORIZED_USERS = {
    "admin2025": "Admin_Master",
    "team_hn": "Team_HaNoi",
    "team_hcm": "Team_HCM"
}

BOT_EMAIL_DISPLAY = "getdulieu@kin-kin-477902.iam.gserviceaccount.com"

# T√™n Sheet
SHEET_CONFIG_NAME = "luu_cau_hinh" 
SHEET_LOG_NAME = "log_lanthucthi"
SHEET_ACTIVITY_NAME = "log_hanh_vi"
SHEET_LOCK_NAME = "sys_lock"
SHEET_SYS_CONFIG = "sys_config"
SHEET_NOTE_NAME = "database_ghi_chu"

# --- ƒê·ªäNH NGHƒ®A C·ªòT ---
COL_BLOCK_NAME = "Block_Name"
COL_STATUS = "Tr·∫°ng th√°i"
COL_DATA_RANGE = "V√πng l·∫•y d·ªØ li·ªáu"
COL_MONTH = "Th√°ng"
COL_SRC_LINK = "Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu"
COL_TGT_LINK = "Link d·ªØ li·ªáu ƒë√≠ch"
COL_SRC_SHEET = "T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc"
COL_TGT_SHEET = "T√™n sheet d·ªØ li·ªáu ƒë√≠ch"
COL_RESULT = "K·∫øt qu·∫£"
COL_LOG_ROW = "D√≤ng d·ªØ li·ªáu"
COL_FILTER = "Dieu_Kien_Loc"      
COL_HEADER = "Lay_Header"         
COL_COPY_FLAG = "Copy_Flag" 

REQUIRED_COLS_CONFIG = [
    COL_BLOCK_NAME, COL_STATUS, COL_DATA_RANGE, COL_MONTH, 
    COL_SRC_LINK, COL_TGT_LINK, COL_TGT_SHEET, COL_SRC_SHEET, 
    COL_RESULT, COL_LOG_ROW, COL_FILTER, COL_HEADER
]

SCHED_COL_BLOCK = "Block_Name"
SCHED_COL_TYPE = "Loai_Lich"
SCHED_COL_VAL1 = "Thong_So_Chinh"
SCHED_COL_VAL2 = "Thong_So_Phu"
REQUIRED_COLS_SCHED = [SCHED_COL_BLOCK, SCHED_COL_TYPE, SCHED_COL_VAL1, SCHED_COL_VAL2]

NOTE_COL_ID = "ID"; NOTE_COL_BLOCK = "T√™n Kh·ªëi"; NOTE_COL_CONTENT = "N·ªôi dung Note"
REQUIRED_COLS_NOTE = [NOTE_COL_ID, NOTE_COL_BLOCK, NOTE_COL_CONTENT]

SYS_COL_LINK = "Link file ngu·ªìn"; SYS_COL_SHEET = "Sheet ngu·ªìn"; SYS_COL_MONTH = "Th√°ng"
DEFAULT_BLOCK_NAME = "Block_Mac_Dinh"
SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']

# C·∫•u h√¨nh Log Buffer
LOG_BUFFER_SIZE = 5 
LOG_FLUSH_INTERVAL = 10 

# ==========================================
# 2. AUTHENTICATION & UTILS (SAFE API)
# ==========================================
def get_creds():
    raw_creds = st.secrets["gcp_service_account"]
    if isinstance(raw_creds, str):
        try: creds_info = json.loads(raw_creds)
        except: return None
    else: creds_info = dict(raw_creds)
    if "private_key" in creds_info: creds_info["private_key"] = creds_info["private_key"].replace("\\n", "\n")
    return service_account.Credentials.from_service_account_info(creds_info, scopes=SCOPES)

def safe_api_call(func, *args, **kwargs):
    """B·ªçc API Call ƒë·ªÉ ch·ªëng l·ªói 429 Quota Exceeded"""
    max_retries = 5
    for i in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            error_str = str(e).lower()
            if "429" in error_str or "quota" in error_str:
                wait_time = (2 ** i) + 5 
                print(f"‚ö†Ô∏è Quota exceeded. Waiting {wait_time}s...")
                time.sleep(wait_time)
            elif i == max_retries - 1: raise e
            else: time.sleep(2)
    return None

def get_sh_with_retry(creds, sheet_id_or_key):
    gc = gspread.authorize(creds)
    return safe_api_call(gc.open_by_key, sheet_id_or_key)

def col_name_to_index(col_name):
    col_name = col_name.upper()
    index = 0
    for char in col_name: index = index * 26 + (ord(char) - ord('A')) + 1
    return index - 1

def extract_id(url):
    if not isinstance(url, str): return None
    if "docs.google.com" in url:
        try: return url.split("/d/")[1].split("/")[0]
        except: return None
    return None

def ensure_sheet_headers(wks, required_columns):
    try:
        current_headers = wks.row_values(1)
        if not current_headers: wks.append_row(required_columns)
    except: pass

# --- [V77] SMART FILTER ENGINE (MULTI CONDITION ; & DATE) ---
def apply_smart_filter_v77(df, filter_str):
    # 1. Ki·ªÉm tra r·ªóng
    if not filter_str or str(filter_str).strip().lower() in ['nan', 'none', 'null', '']:
        return df, None

    # 2. T√°ch ƒëi·ªÅu ki·ªán b·∫±ng d·∫•u CH·∫§M PH·∫®Y (;)
    conditions = str(filter_str).split(';')
    
    current_df = df.copy()
    
    for cond in conditions:
        fs = cond.strip()
        if not fs: continue 
        
        # Danh s√°ch to√°n t·ª≠
        operators = [" contains ", "==", "!=", ">=", "<=", ">", "<", "="]
        selected_op = None
        for op in operators:
            if op in fs: selected_op = op; break
                
        if not selected_op: 
            return None, f"L·ªói c√∫ ph√°p: Kh√¥ng t√¨m th·∫•y to√°n t·ª≠ trong '{fs}'"

        parts = fs.split(selected_op, 1)
        user_col = parts[0].strip().replace("`", "").replace("'", "").replace('"', "")
        
        # T√¨m c·ªôt
        real_col_name = None
        if user_col in current_df.columns: 
            real_col_name = user_col
        else:
            for col in current_df.columns:
                if str(col).strip() == user_col: real_col_name = col; break
        
        if not real_col_name: 
            return None, f"Kh√¥ng t√¨m th·∫•y c·ªôt '{user_col}'"

        # X·ª≠ l√Ω gi√° tr·ªã ng∆∞·ªùi d√πng nh·∫≠p
        user_val = parts[1].strip()
        if (user_val.startswith("'") and user_val.endswith("'")) or (user_val.startswith('"') and user_val.endswith('"')):
            clean_val = user_val[1:-1]
        else:
            clean_val = user_val

        # --- TH·ª∞C THI L·ªåC ---
        try:
            col_series = current_df[real_col_name]
            col_str = col_series.astype(str)

            if selected_op == " contains ":
                current_df = current_df[col_str.str.contains(clean_val, case=False, na=False)]
            
            elif selected_op in ["=", "=="]:
                current_df = current_df[col_str == str(clean_val)]
                
            elif selected_op == "!=":
                current_df = current_df[col_str != str(clean_val)]
                
            else:
                # So s√°nh L·ªõn/B√© (S·ªë ho·∫∑c Ng√†y th√°ng d·∫°ng chu·ªói)
                is_numeric = False
                try:
                    numeric_col = pd.to_numeric(col_series, errors='raise')
                    numeric_val = float(clean_val)
                    is_numeric = True
                except: 
                    is_numeric = False

                if is_numeric:
                    if selected_op == ">": current_df = current_df[numeric_col > numeric_val]
                    if selected_op == "<": current_df = current_df[numeric_col < numeric_val]
                    if selected_op == ">=": current_df = current_df[numeric_col >= numeric_val]
                    if selected_op == "<=": current_df = current_df[numeric_col <= numeric_val]
                else:
                    # So s√°nh chu·ªói (Date)
                    if selected_op == ">": current_df = current_df[col_str > str(clean_val)]
                    if selected_op == "<": current_df = current_df[col_str < str(clean_val)]
                    if selected_op == ">=": current_df = current_df[col_str >= str(clean_val)]
                    if selected_op == "<=": current_df = current_df[col_str <= str(clean_val)]
                
        except Exception as e:
            return None, f"L·ªói x·ª≠ l√Ω ƒëi·ªÅu ki·ªán '{fs}': {str(e)}"

    return current_df, None

# --- LOGGING SYSTEM ---
def init_log_buffer():
    if 'log_buffer' not in st.session_state: st.session_state['log_buffer'] = []
    if 'last_log_flush' not in st.session_state: st.session_state['last_log_flush'] = time.time()

def flush_logs(creds, force=False):
    buffer = st.session_state.get('log_buffer', [])
    last_flush = st.session_state.get('last_log_flush', 0)
    if (force or len(buffer) >= LOG_BUFFER_SIZE or (time.time() - last_flush > LOG_FLUSH_INTERVAL)) and buffer:
        try:
            sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
            try: wks = sh.worksheet(SHEET_ACTIVITY_NAME)
            except: 
                wks = sh.add_worksheet(SHEET_ACTIVITY_NAME, rows=1000, cols=4)
                wks.append_row(["Th·ªùi gian", "Ng∆∞·ªùi d√πng", "H√†nh vi", "Tr·∫°ng th√°i"])
            safe_api_call(wks.append_rows, buffer)
            st.session_state['log_buffer'] = []
            st.session_state['last_log_flush'] = time.time()
        except: pass

def log_user_action_buffered(creds, user_id, action, status="", force_flush=False):
    init_log_buffer()
    tz = pytz.timezone('Asia/Ho_Chi_Minh')
    log_entry = [datetime.now(tz).strftime("%d/%m/%Y %H:%M:%S"), user_id, action, status]
    st.session_state['log_buffer'].append(log_entry)
    flush_logs(creds, force=force_flush)

def detect_df_changes(df_old, df_new):
    if len(df_old) != len(df_new): return f"Thay ƒë·ªïi d√≤ng: {len(df_old)} -> {len(df_new)}"
    changes = []
    ignore_cols = [COL_BLOCK_NAME, COL_LOG_ROW, COL_RESULT, "STT", COL_COPY_FLAG, "_index"]
    compare_cols = [c for c in df_new.columns if c not in ignore_cols and c in df_old.columns]
    dfo = df_old.reset_index(drop=True); dfn = df_new.reset_index(drop=True)
    for i in range(len(dfo)):
        for col in compare_cols:
            val_old = str(dfo.at[i, col]).strip(); val_new = str(dfn.at[i, col]).strip()
            if val_old != val_new:
                vo = (val_old[:15] + '..') if len(val_old) > 15 else val_old
                vn = (val_new[:15] + '..') if len(val_new) > 15 else val_new
                changes.append(f"D√≤ng {i+1} [{col}]: {vo} -> {vn}")
                if len(changes) >= 3: 
                    changes.append("..."); return " | ".join(changes)
    return " | ".join(changes) if changes else "Kh√¥ng c√≥ thay ƒë·ªïi n·ªôi dung"

# --- LOGIN ---
def check_login():
    if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False
    if 'current_user_id' not in st.session_state: st.session_state['current_user_id'] = "Unknown"
    if "auto_key" in st.query_params:
        key = st.query_params["auto_key"]
        if key in AUTHORIZED_USERS:
            st.session_state['logged_in'] = True; st.session_state['current_user_id'] = AUTHORIZED_USERS[key]; return True
    if st.session_state['logged_in']: return True
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.header("üõ°Ô∏è ƒêƒÉng nh·∫≠p")
        pwd = st.text_input("M·∫≠t kh·∫©u:", type="password")
        if st.button("ƒêƒÉng Nh·∫≠p", use_container_width=True):
            if pwd in AUTHORIZED_USERS:
                st.session_state['logged_in'] = True; st.session_state['current_user_id'] = AUTHORIZED_USERS[pwd]
                log_user_action_buffered(get_creds(), AUTHORIZED_USERS[pwd], "ƒêƒÉng nh·∫≠p", "Th√†nh c√¥ng", force_flush=True)
                st.rerun()
            else: st.error("Sai m·∫≠t kh·∫©u")
    return False

# ==========================================
# 3. SYSTEM MANAGERS
# ==========================================
def get_system_lock_status(creds):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        try: wks = sh.worksheet(SHEET_LOCK_NAME)
        except: wks = sh.add_worksheet(SHEET_LOCK_NAME, rows=10, cols=5); wks.update([["is_locked", "user", "time_start"], ["FALSE", "", ""]]); return False, "", ""
        val = wks.cell(2, 1).value; user = wks.cell(2, 2).value; time_str = wks.cell(2, 3).value
        if val == "TRUE":
            try:
                if (datetime.now() - datetime.strptime(time_str, "%d/%m/%Y %H:%M:%S")).total_seconds() > 300: return False, "", ""
            except: pass
            return True, user, time_str
        return False, "", ""
    except: return False, "", ""

def acquire_lock(creds, user_id):
    is_locked, locking_user, t = get_system_lock_status(creds)
    if is_locked and locking_user != user_id: return False
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_LOCK_NAME)
        now_str = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        wks.update("A2:C2", [["TRUE", user_id, now_str]])
        return True
    except: return False

def release_lock(creds, user_id):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_LOCK_NAME)
        val = wks.cell(2, 2).value
        if val == user_id: wks.update("A2:C2", [["FALSE", "", ""]])
    except: pass

def load_notes_data(creds):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        try: wks = sh.worksheet(SHEET_NOTE_NAME)
        except: wks = sh.add_worksheet(SHEET_NOTE_NAME, rows=100, cols=5); ensure_sheet_headers(wks, REQUIRED_COLS_NOTE)
        ensure_sheet_headers(wks, REQUIRED_COLS_NOTE)
        df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str)
        if df.empty: return pd.DataFrame(columns=REQUIRED_COLS_NOTE)
        return df.dropna(how='all')
    except: return pd.DataFrame(columns=REQUIRED_COLS_NOTE)

def save_notes_data(df_notes, creds, user_id, block_name):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_NOTE_NAME)
        if not df_notes.empty:
            for idx, row in df_notes.iterrows():
                if not row[NOTE_COL_ID]: df_notes.at[idx, NOTE_COL_ID] = str(uuid.uuid4())[:8]
        set_with_dataframe(wks, df_notes, row=1, col=1)
        log_user_action_buffered(creds, user_id, "L∆∞u Ghi Ch√∫", f"C·∫≠p nh·∫≠t note cho {block_name}", force_flush=True)
        return True
    except: return False

@st.dialog("üìù Note", width="large")
def show_note_popup(creds, all_blocks, user_id):
    if 'df_notes_temp' not in st.session_state: st.session_state['df_notes_temp'] = load_notes_data(creds)
    df_notes = st.session_state['df_notes_temp']
    edited_notes = st.data_editor(
        df_notes, num_rows="dynamic", use_container_width=True,
        column_config={
            NOTE_COL_ID: st.column_config.TextColumn("ID", disabled=True, width="small"),
            NOTE_COL_BLOCK: st.column_config.SelectboxColumn("Kh·ªëi", options=all_blocks, required=True),
            NOTE_COL_CONTENT: st.column_config.TextColumn("N·ªôi dung", width="large")
        }, key="note_popup"
    )
    if st.button("üíæ L∆∞u Note", type="primary"):
        blk_ref = edited_notes[NOTE_COL_BLOCK].iloc[0] if not edited_notes.empty else "All"
        if save_notes_data(edited_notes, creds, user_id, blk_ref):
            st.success("ƒê√£ l∆∞u!"); time.sleep(1); st.rerun()

def load_scheduler_config(creds):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        try: wks = sh.worksheet(SHEET_SYS_CONFIG)
        except: 
            wks = sh.add_worksheet(SHEET_SYS_CONFIG, rows=50, cols=5)
            wks.append_row(REQUIRED_COLS_SCHED)
        ensure_sheet_headers(wks, REQUIRED_COLS_SCHED)
        df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str)
        if SCHED_COL_BLOCK not in df.columns: return pd.DataFrame(columns=REQUIRED_COLS_SCHED)
        return df.dropna(how='all')
    except: return pd.DataFrame(columns=REQUIRED_COLS_SCHED)

def save_scheduler_config(df_sched, creds, user_id, type_run, v1, v2):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_SYS_CONFIG)
        cols = REQUIRED_COLS_SCHED
        for c in cols:
            if c not in df_sched.columns: df_sched[c] = ""
        wks.clear(); set_with_dataframe(wks, df_sched[cols].fillna(""), row=1, col=1)
        msg = f"C√†i ƒë·∫∑t: {type_run} | {v1} {v2}".strip()
        log_user_action_buffered(creds, user_id, "C√†i L·ªãch Ch·∫°y", msg, force_flush=True)
        return True
    except: return False

def fetch_activity_logs(creds, limit=50):
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_ACTIVITY_NAME)
        df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str)
        if df.empty: return pd.DataFrame()
        return df.tail(limit).iloc[::-1]
    except: return pd.DataFrame()

def write_detailed_log(creds, log_data_list):
    if not log_data_list: return
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        try: wks = sh.worksheet(SHEET_LOG_NAME)
        except: 
            wks = sh.add_worksheet(SHEET_LOG_NAME, rows=1000, cols=15)
            wks.append_row(["Th·ªùi gian", "V√πng l·∫•y", "Th√°ng", "User", "Link Ngu·ªìn", "Link ƒê√≠ch", "Sheet ƒê√≠ch", "Sheet Ngu·ªìn", "K·∫øt Qu·∫£", "S·ªë D√≤ng", "Range", "Block"])
        
        cleaned_list = []
        for row in log_data_list:
            cleaned_list.append([str(x) for x in row])
            
        safe_api_call(wks.append_rows, cleaned_list)
    except Exception as e:
        st.warning(f"L·ªói ghi log (V78): {str(e)}")

# ==========================================
# 4. CORE ETL
# ==========================================
def fetch_data_v4(row_config, creds, target_headers=None):
    link_src = str(row_config.get(COL_SRC_LINK, '')).strip()
    source_label = str(row_config.get(COL_SRC_SHEET, '')).strip()
    month_val = str(row_config.get(COL_MONTH, ''))
    
    # 1. Range
    raw_range = str(row_config.get(COL_DATA_RANGE, '')).strip()
    if raw_range.lower() in ['nan', 'none', 'null', '', 'l·∫•y h·∫øt']:
        data_range_str = "L·∫•y h·∫øt"
    else:
        data_range_str = raw_range

    # 2. Filter
    raw_filter = str(row_config.get(COL_FILTER, '')).strip()
    if raw_filter.lower() in ['nan', 'none', 'null']: raw_filter = ""
    
    include_header = str(row_config.get(COL_HEADER, 'FALSE')).strip().upper() == 'TRUE'
    sheet_id = extract_id(link_src)
    if not sheet_id: return None, sheet_id, "Link l·ªói"
    
    try:
        sh_source = get_sh_with_retry(creds, sheet_id)
        if source_label:
            try: wks_source = sh_source.worksheet(source_label)
            except: return None, sheet_id, f"‚ùå 404 Sheet: {source_label}"
        else: wks_source = sh_source.sheet1
            
        data = safe_api_call(wks_source.get_all_values)
        if not data: return pd.DataFrame(), sheet_id, "Sheet tr·∫Øng/L·ªói t·∫£i"

        header_row = data[0]
        body_rows = data[1:]
        
        unique_headers = []
        seen = {}
        for col in header_row:
            if col in seen:
                seen[col] += 1
                unique_headers.append(f"{col}_{seen[col]}")
            else:
                seen[col] = 0
                unique_headers.append(col)
        
        df_working = pd.DataFrame(body_rows, columns=unique_headers)

        if target_headers:
            num_src = len(df_working.columns); num_tgt = len(target_headers)
            min_cols = min(num_src, num_tgt)
            old_cols = df_working.columns.tolist()
            rename_map = {old_cols[i]: target_headers[i] for i in range(min_cols)}
            df_working = df_working.rename(columns=rename_map)
            if num_src > num_tgt: df_working = df_working.iloc[:, :num_tgt]

        if data_range_str != "L·∫•y h·∫øt" and ":" in data_range_str:
            try:
                s_str, e_str = data_range_str.split(":")
                s_idx = col_name_to_index(s_str.strip()); e_idx = col_name_to_index(e_str.strip())
                if s_idx >= 0: df_working = df_working.iloc[:, s_idx : e_idx + 1]
            except: pass

        if raw_filter:
            # [V77] S·ª≠ d·ª•ng h√†m Filter m·ªõi
            df_filtered, err = apply_smart_filter_v77(df_working, raw_filter)
            if err: return None, sheet_id, f"‚ö†Ô∏è {err}"
            df_working = df_filtered

        if include_header:
            df_header_row = pd.DataFrame([df_working.columns.tolist()], columns=df_working.columns)
            df_final = pd.concat([df_header_row, df_working], ignore_index=True)
        else:
            df_final = df_working

        df_final = df_final.astype(str).replace(['nan', 'None', '<NA>', 'null'], '')
        
        df_final[SYS_COL_LINK] = link_src.strip()
        df_final[SYS_COL_SHEET] = source_label.strip()
        df_final[SYS_COL_MONTH] = month_val.strip()
        
        return df_final, sheet_id, "Th√†nh c√¥ng"

    except Exception as e: return None, sheet_id, f"L·ªói t·∫£i: {str(e)}"

def get_rows_to_delete_dynamic(wks, keys_to_delete, log_container):
    all_values = safe_api_call(wks.get_all_values)
    if not all_values: return []
    headers = all_values[0]
    try:
        idx_link = headers.index(SYS_COL_LINK); idx_sheet = headers.index(SYS_COL_SHEET); idx_month = headers.index(SYS_COL_MONTH)
    except ValueError: return [] 
    rows_to_delete = []
    for i, row in enumerate(all_values[1:], start=2): 
        l = row[idx_link].strip() if len(row) > idx_link else ""
        s = row[idx_sheet].strip() if len(row) > idx_sheet else ""
        m = row[idx_month].strip() if len(row) > idx_month else ""
        if (l, s, m) in keys_to_delete: rows_to_delete.append(i)
    return rows_to_delete

def batch_delete_rows(sh, sheet_id, row_indices, log_container=None):
    if not row_indices: return
    row_indices.sort(reverse=True) 
    ranges = []
    if len(row_indices) > 0:
        start = row_indices[0]; end = start
        for r in row_indices[1:]:
            if r == start - 1: start = r
            else: ranges.append((start, end)); start = r; end = r
        ranges.append((start, end))
    requests = []
    for start, end in ranges:
        requests.append({"deleteDimension": {"range": {"sheetId": sheet_id, "dimension": "ROWS", "startIndex": start - 1, "endIndex": end}}})
    batch_size = 100
    for i in range(0, len(requests), batch_size):
        if log_container: log_container.write(f"‚úÇÔ∏è X√≥a batch {i//batch_size + 1}...")
        safe_api_call(sh.batch_update, {'requests': requests[i:i+batch_size]})
        time.sleep(1)

def write_strict_sync_v2(tasks_list, target_link, target_sheet_name, creds, log_container):
    result_map = {} 
    try:
        target_id = extract_id(target_link)
        if not target_id: return False, "Link l·ªói", {}
        sh = get_sh_with_retry(creds, target_id)
        real_sheet_name = str(target_sheet_name).strip() or "Tong_Hop_Data"
        log_container.write(f"üìÇ ƒê√≠ch: ...{target_link[-10:]} | Sheet: {real_sheet_name}")
        
        all_titles = [s.title for s in safe_api_call(sh.worksheets)]
        if real_sheet_name in all_titles:
            wks = sh.worksheet(real_sheet_name)
        else:
            wks = sh.add_worksheet(title=real_sheet_name, rows=1000, cols=20)
            log_container.write(f"‚ú® T·∫°o m·ªõi sheet: {real_sheet_name}")
        
        df_new_all = pd.DataFrame()
        for df, src_link, r_idx in tasks_list:
            df_new_all = pd.concat([df_new_all, df], ignore_index=True)
        
        if df_new_all.empty: return True, "No Data", {}

        existing_headers = safe_api_call(wks.row_values, 1)
        if not existing_headers:
            final_headers = df_new_all.columns.tolist()
            wks.update(range_name="A1", values=[final_headers])
            existing_headers = final_headers
            log_container.write("üÜï T·∫°o Header m·ªõi.")
        else:
            updated = existing_headers.copy(); added = False
            for col in [SYS_COL_LINK, SYS_COL_SHEET, SYS_COL_MONTH]:
                if col not in updated: updated.append(col); added = True
            if added: wks.update(range_name="A1", values=[updated]); existing_headers = updated; log_container.write("‚ûï C·∫≠p nh·∫≠t c·ªôt h·ªá th·ªëng.")

        df_aligned = pd.DataFrame()
        for col in existing_headers:
            if col in df_new_all.columns: df_aligned[col] = df_new_all[col]
            else: df_aligned[col] = ""
        
        keys = set()
        for idx, row in df_new_all.iterrows():
            keys.add((str(row[SYS_COL_LINK]).strip(), str(row[SYS_COL_SHEET]).strip(), str(row[SYS_COL_MONTH]).strip()))
        
        log_container.write("üîç Qu√©t d·ªØ li·ªáu c≈©...")
        rows_to_del = get_rows_to_delete_dynamic(wks, keys, log_container)
        if rows_to_del:
            log_container.write(f"‚úÇÔ∏è X√≥a {len(rows_to_del)} d√≤ng c≈©...")
            batch_delete_rows(sh, wks.id, rows_to_del, log_container)
            log_container.write("‚úÖ ƒê√£ x√≥a.")
        
        log_container.write(f"üöÄ Ghi {len(df_aligned)} d√≤ng m·ªõi...")
        start_row = len(safe_api_call(wks.get_all_values)) + 1
        
        chunk_size = 5000
        new_vals = df_aligned.fillna('').values.tolist()
        for i in range(0, len(new_vals), chunk_size):
            safe_api_call(wks.append_rows, new_vals[i:i+chunk_size], value_input_option='USER_ENTERED')
            time.sleep(1)

        current_cursor = start_row
        for df, src_link, r_idx in tasks_list:
            count = len(df)
            end = current_cursor + count - 1
            result_map[r_idx] = ("Th√†nh c√¥ng", f"{current_cursor} - {end}", count)
            current_cursor += count
            
        return True, f"C·∫≠p nh·∫≠t {len(df_aligned)} d√≤ng", result_map

    except Exception as e: return False, f"L·ªói Ghi: {str(e)}", {}

# --- PIPELINE ---
def verify_access_fast(url, creds):
    sheet_id = extract_id(url)
    if not sheet_id: return False, "Link l·ªói"
    try: get_sh_with_retry(creds, sheet_id); return True, "OK"
    except: return False, "Ch·∫∑n quy·ªÅn"

def check_permissions_ui(rows, creds, container, user_id):
    # [V78] Logic Qu√©t Quy·ªÅn Th√¥ng Minh (Source vs Target)
    log_user_action_buffered(creds, user_id, "Qu√©t Quy·ªÅn", "B·∫Øt ƒë·∫ßu...", force_flush=False)
    
    src_links = set()
    tgt_links = set()
    
    for r in rows:
        s_link = str(r.get(COL_SRC_LINK, '')).strip()
        t_link = str(r.get(COL_TGT_LINK, '')).strip()
        if "docs.google.com" in s_link: src_links.add(s_link)
        if "docs.google.com" in t_link: tgt_links.add(t_link)
    
    all_unique_links = list(src_links.union(tgt_links))
    total = len(all_unique_links)
    
    if total == 0:
        container.info("Kh√¥ng t√¨m th·∫•y link Google Sheet n√†o ƒë·ªÉ ki·ªÉm tra.")
        return

    prog = container.progress(0)
    err_count = 0
    
    for i, link in enumerate(all_unique_links):
        prog.progress((i + 1) / total)
        time.sleep(0.2)
        
        ok, msg = verify_access_fast(link, creds)
        
        if not ok:
            err_count += 1
            error_msgs = []
            if link in src_links:
                error_msgs.append("Link Ngu·ªìn ch∆∞a c·∫•p quy·ªÅn -> vui l√≤ng c·∫•p quy·ªÅn XEM cho bot")
            if link in tgt_links:
                error_msgs.append("Link ƒê√≠ch ch∆∞a c·∫•p quy·ªÅn -> vui l√≤ng c·∫•p quy·ªÅn CH·ªàNH S·ª¨A cho bot")
            final_msg = " & ".join(error_msgs)
            container.error(f"‚ùå {link}\nüëâ {final_msg}")
    
    if err_count == 0:
        container.success("‚úÖ Tuy·ªát v·ªùi! Bot ƒë√£ truy c·∫≠p ƒë∆∞·ª£c t·∫•t c·∫£ c√°c file.")
    else:
        container.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {err_count} link ch∆∞a c·∫•p ƒë·ªß quy·ªÅn. Vui l√≤ng ki·ªÉm tra l·∫°i.")
        
    log_user_action_buffered(creds, user_id, "Qu√©t Quy·ªÅn", f"Ho√†n t·∫•t. L·ªói: {err_count}", force_flush=True)

def process_pipeline_mixed(rows_to_run, user_id, block_name_run, status_container):
    creds = get_creds()
    if not acquire_lock(creds, user_id): 
        st.error("‚ö†Ô∏è H·ªá th·ªëng ƒëang b·∫≠n. Vui l√≤ng th·ª≠ l·∫°i sau."); return False, {}, 0
    
    log_user_action_buffered(creds, user_id, f"Ch·∫°y: {block_name_run}", "ƒêang x·ª≠ l√Ω...", force_flush=True)
    try:
        grouped = defaultdict(list)
        for r in rows_to_run:
            if str(r.get(COL_STATUS, '')).strip() == "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t":
                grouped[(str(r.get(COL_TGT_LINK, '')).strip(), str(r.get(COL_TGT_SHEET, '')).strip())].append(r)
        
        final_res_map = {}; all_ok = True; total_rows = 0; log_ents = []
        tz = pytz.timezone('Asia/Ho_Chi_Minh'); now = datetime.now(tz).strftime("%d/%m/%Y %H:%M:%S")

        for idx, ((t_link, t_sheet), group_rows) in enumerate(grouped.items()):
            with status_container.expander(f"Processing File {idx+1}: ...{t_link[-10:]}", expanded=True):
                target_headers = []
                try:
                    tid = extract_id(t_link)
                    if tid:
                        sh_t = get_sh_with_retry(creds, tid)
                        all_titles = [s.title for s in safe_api_call(sh_t.worksheets)]
                        if t_sheet in all_titles:
                            wks_t = sh_t.worksheet(t_sheet)
                            target_headers = safe_api_call(wks_t.row_values, 1)
                except: pass

                tasks = []
                for i, r in enumerate(group_rows):
                    lnk = r.get(COL_SRC_LINK, ''); lbl = r.get(COL_SRC_SHEET, '')
                    row_idx = r.get('_index', -1)
                    st.write(f"‚¨áÔ∏è T·∫£i: {lnk[-10:]} ({lbl})")
                    df, sid, msg = fetch_data_v4(r, creds, target_headers)
                    time.sleep(1.5)
                    
                    if df is not None: 
                        tasks.append((df, lnk, row_idx))
                        total_rows += len(df)
                    else: 
                        st.error(f"‚ùå {msg}")
                        final_res_map[row_idx] = ("L·ªói t·∫£i", "", 0)
                    del df; gc.collect()

                if tasks:
                    ok, msg, batch_res_map = write_strict_sync_v2(tasks, t_link, t_sheet, creds, st)
                    if not ok: st.error(msg); all_ok = False
                    else: st.success(msg)
                    final_res_map.update(batch_res_map)
                    del tasks; gc.collect()
                
                for r in group_rows:
                    row_idx = r.get('_index', -1)
                    res_status, res_range, res_count = final_res_map.get(row_idx, ("L·ªói", "", 0))
                    
                    log_ents.append([
                        now, r.get(COL_DATA_RANGE), r.get(COL_MONTH), user_id, 
                        r.get(COL_SRC_LINK), t_link, t_sheet, r.get(COL_SRC_SHEET), 
                        res_status, res_count, res_range, block_name_run
                    ])
        
        write_detailed_log(creds, log_ents)
        status_msg = f"Ho√†n t·∫•t: X·ª≠ l√Ω {total_rows} d√≤ng. L·ªói: {not all_ok}"
        log_user_action_buffered(creds, user_id, f"K·∫øt qu·∫£ ch·∫°y {block_name_run}", status_msg, force_flush=True)
        
        return all_ok, final_res_map, total_rows
    finally: release_lock(creds, user_id)

# ==========================================
# 5. UI & MAIN
# ==========================================
@st.cache_data
def load_full_config(_creds):
    sh = get_sh_with_retry(_creds, st.secrets["gcp_service_account"]["history_sheet_id"])
    wks = sh.worksheet(SHEET_CONFIG_NAME)
    ensure_sheet_headers(wks, REQUIRED_COLS_CONFIG)
    df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str).dropna(how='all')
    if df.empty: return pd.DataFrame(columns=REQUIRED_COLS_CONFIG)
    
    df[COL_BLOCK_NAME] = df[COL_BLOCK_NAME].replace('', DEFAULT_BLOCK_NAME).fillna(DEFAULT_BLOCK_NAME)
    # [V78] Clean old cols
    df[COL_HEADER] = df[COL_HEADER].replace('', 'FALSE').fillna('FALSE')
    if 'STT' in df.columns: df = df.drop(columns=['STT'])
    if 'Che_Do_Ghi' in df.columns: df = df.drop(columns=['Che_Do_Ghi'])
    return df

def save_block_config_to_sheet(df_ui, blk_name, creds, uid):
    if not acquire_lock(creds, uid): st.error("Busy!"); return
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_CONFIG_NAME)
        
        df_svr = get_as_dataframe(wks, evaluate_formulas=True, dtype=str).dropna(how='all')
        if COL_BLOCK_NAME not in df_svr.columns: df_svr[COL_BLOCK_NAME] = DEFAULT_BLOCK_NAME
        
        df_old_blk = df_svr[df_svr[COL_BLOCK_NAME] == blk_name].copy().reset_index(drop=True)
        df_new_blk = df_ui.copy().reset_index(drop=True)
        
        action_type = "C·∫≠p nh·∫≠t Kh·ªëi"
        if df_old_blk.empty and not df_new_blk.empty:
            action_type = "T·∫°o m·ªõi Kh·ªëi"
            change_msg = f"Kh·ªüi t·∫°o {len(df_new_blk)} d√≤ng c·∫•u h√¨nh."
        else:
            change_msg = detect_df_changes(df_old_blk, df_new_blk)
        
        if "Kh√¥ng c√≥ thay ƒë·ªïi" in change_msg:
            change_msg = "ƒê√£ l∆∞u (Kh√¥ng c√≥ thay ƒë·ªïi n·ªôi dung)"
        
        log_user_action_buffered(creds, uid, f"{action_type} {blk_name}", change_msg, force_flush=True)
        
        df_oth = df_svr[df_svr[COL_BLOCK_NAME] != blk_name]
        if 'STT' in df_new_blk.columns: df_new_blk = df_new_blk.drop(columns=['STT'])
        if COL_COPY_FLAG in df_new_blk.columns: df_new_blk = df_new_blk.drop(columns=[COL_COPY_FLAG])
        if '_index' in df_new_blk.columns: df_new_blk = df_new_blk.drop(columns=['_index'])
        if 'Che_Do_Ghi' in df_new_blk.columns: df_new_blk = df_new_blk.drop(columns=['Che_Do_Ghi'])
        
        df_fin = pd.concat([df_oth, df_new_blk], ignore_index=True).astype(str).replace(['nan', 'None'], '')
        wks.clear(); set_with_dataframe(wks, df_fin, row=1, col=1)
        st.toast("Saved!", icon="üíæ")
    finally: release_lock(creds, uid)

def rename_block_action(old, new, creds, uid):
    if not acquire_lock(creds, uid): return False
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"]); wks = sh.worksheet(SHEET_CONFIG_NAME)
        df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str)
        df.loc[df[COL_BLOCK_NAME] == old, COL_BLOCK_NAME] = new
        wks.clear(); set_with_dataframe(wks, df, row=1, col=1)
        log_user_action_buffered(creds, uid, "ƒê·ªïi t√™n Kh·ªëi", f"{old} -> {new}", force_flush=True)
        return True
    finally: release_lock(creds, uid)

def delete_block_direct(blk, creds, uid):
    if not acquire_lock(creds, uid): return
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"]); wks = sh.worksheet(SHEET_CONFIG_NAME)
        df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str).dropna(how='all')
        df_new = df[df[COL_BLOCK_NAME] != blk]
        wks.clear(); set_with_dataframe(wks, df_new, row=1, col=1)
        log_user_action_buffered(creds, uid, "X√≥a Kh·ªëi", f"ƒê√£ x√≥a: {blk}", force_flush=True)
    finally: release_lock(creds, uid)

def save_full_direct(df, creds, uid):
    if not acquire_lock(creds, uid): return
    try:
        sh = get_sh_with_retry(creds, st.secrets["gcp_service_account"]["history_sheet_id"]); wks = sh.worksheet(SHEET_CONFIG_NAME)
        df = df.astype(str).replace(['nan', 'None'], '')
        wks.clear(); set_with_dataframe(wks, df, row=1, col=1)
    finally: release_lock(creds, uid)

def main_ui():
    init_log_buffer()
    if not check_login(): return
    uid = st.session_state['current_user_id']; creds = get_creds()
    c1, c2 = st.columns([3, 1])
    with c1: st.title("üíé TOOL 2.0 l·∫•y d·ªØ li·ªáu from GG sheet to GG sheet ", help="V78: Full Features"); st.caption(f"User: {uid}")
    with c2: st.code(BOT_EMAIL_DISPLAY)

    with st.sidebar:
        if 'df_full_config' not in st.session_state: st.session_state['df_full_config'] = load_full_config(creds)
        if st.button("üîÑ Reload"): st.cache_data.clear(); st.session_state['df_full_config'] = load_full_config(creds); st.rerun()
        df_cfg = st.session_state['df_full_config']
        blks = df_cfg[COL_BLOCK_NAME].unique().tolist() if not df_cfg.empty else [DEFAULT_BLOCK_NAME]
        if 'target_block_display' not in st.session_state: st.session_state['target_block_display'] = blks[0]
        sel_blk = st.selectbox("Ch·ªçn Kh·ªëi:", blks, index=blks.index(st.session_state['target_block_display']) if st.session_state['target_block_display'] in blks else 0)
        st.session_state['target_block_display'] = sel_blk 

        if st.button("¬©Ô∏è Copy Block"):
             new_b = f"{sel_blk}_copy"
             bd = df_cfg[df_cfg[COL_BLOCK_NAME] == sel_blk].copy(); bd[COL_BLOCK_NAME] = new_b
             st.session_state['df_full_config'] = pd.concat([df_cfg, bd], ignore_index=True)
             save_block_config_to_sheet(bd, new_b, creds, uid); st.session_state['target_block_display'] = new_b; st.rerun()

        with st.expander("‚è∞ L·ªãch ch·∫°y t·ª± ƒë·ªông", expanded=True):
            df_sched = load_scheduler_config(creds)
            if SCHED_COL_BLOCK in df_sched.columns: curr_row = df_sched[df_sched[SCHED_COL_BLOCK] == sel_blk]
            else: curr_row = pd.DataFrame()
            d_type = str(curr_row.iloc[0].get(SCHED_COL_TYPE, "Kh√¥ng ch·∫°y")) if not curr_row.empty else "Kh√¥ng ch·∫°y"
            d_val1 = str(curr_row.iloc[0].get(SCHED_COL_VAL1, "")) if not curr_row.empty else ""
            d_val2 = str(curr_row.iloc[0].get(SCHED_COL_VAL2, "")) if not curr_row.empty else ""
            
            if d_type != "Kh√¥ng ch·∫°y": st.info(f"‚úÖ ƒêang c√†i: {d_type} | {d_val1} {d_val2}")
            else: st.info("‚ö™ Ch∆∞a c√†i ƒë·∫∑t l·ªãch")

            opts = ["Kh√¥ng ch·∫°y", "Ch·∫°y theo ph√∫t", "H√†ng ng√†y", "H√†ng tu·∫ßn", "H√†ng th√°ng"]
            new_type = st.selectbox("Ki·ªÉu:", opts, index=opts.index(d_type) if d_type in opts else 0)
            n_val1 = d_val1; n_val2 = d_val2
            
            if new_type == "Ch·∫°y theo ph√∫t":
                v = int(d_val1) if (d_type == "Ch·∫°y theo ph√∫t" and d_val1.isdigit()) else 50
                n_val1 = str(st.slider("T·∫ßn su·∫•t (Ph√∫t):", 30, 180, max(30, v), 10))
                # [V74] Th√™m gi·ªù b·∫Øt ƒë·∫ßu
                hrs = [f"{i:02d}:00" for i in range(24)]
                idx_h = hrs.index(d_val2) if (d_type=="Ch·∫°y theo ph√∫t" and d_val2 in hrs) else 8
                n_val2 = st.selectbox("Gi·ªù b·∫Øt ƒë·∫ßu:", hrs, index=idx_h)
            
            elif new_type == "H√†ng ng√†y":
                hours = [f"{i:02d}:00" for i in range(24)]
                idx = hours.index(d_val1) if (d_type=="H√†ng ng√†y" and d_val1 in hours) else 8
                n_val1 = st.selectbox("Gi·ªù:", hours, index=idx)
            elif new_type == "H√†ng tu·∫ßn":
                hours = [f"{i:02d}:00" for i in range(24)]
                days = ["T2", "T3", "T4", "T5", "T6", "T7", "CN"]
                od = [x.strip() for x in d_val2.split(",")] if d_type=="H√†ng tu·∫ßn" else []
                sel_d = st.multiselect("Th·ª©:", days, default=[d for d in od if d in days])
                n_val1 = st.selectbox("Gi·ªù:", hours, index=hours.index(d_val1) if (d_type=="H√†ng tu·∫ßn" and d_val1 in hours) else 8)
                n_val2 = ",".join(sel_d)
            elif new_type == "H√†ng th√°ng":
                dates = [str(i) for i in range(1,32)]
                od = [x.strip() for x in d_val2.split(",")] if d_type=="H√†ng th√°ng" else []
                sel_d = st.multiselect("Ng√†y:", dates, default=[d for d in od if d in dates])
                n_val1 = st.selectbox("Gi·ªù:", [f"{i:02d}:00" for i in range(24)], index=8)
                n_val2 = ",".join(sel_d)

            if st.button("üíæ L∆∞u L·ªãch"):
                if SCHED_COL_BLOCK in df_sched.columns: df_sched = df_sched[df_sched[SCHED_COL_BLOCK] != sel_blk]
                new_r = {SCHED_COL_BLOCK: sel_blk, SCHED_COL_TYPE: new_type, SCHED_COL_VAL1: n_val1, SCHED_COL_VAL2: n_val2}
                df_sched = pd.concat([df_sched, pd.DataFrame([new_r])], ignore_index=True)
                save_scheduler_config(df_sched, creds, uid, new_type, n_val1, n_val2)
                st.success("ƒê√£ l∆∞u!"); time.sleep(1); st.rerun()

        with st.expander("‚öôÔ∏è Manager"):
            new_b = st.text_input("New Name:")
            if st.button("‚ûï Add"):
                row = {c: "" for c in df_cfg.columns}; row[COL_BLOCK_NAME] = new_b; row[COL_STATUS] = "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t"
                st.session_state['df_full_config'] = pd.concat([df_cfg, pd.DataFrame([row])], ignore_index=True)
                st.session_state['target_block_display'] = new_b; st.rerun()
            rn = st.text_input("Rename to:", value=sel_blk)
            if st.button("‚úèÔ∏è Rename") and rn != sel_blk:
                if rename_block_action(sel_blk, rn, creds, uid): st.cache_data.clear(); del st.session_state['df_full_config']; st.session_state['target_block_display'] = rn; st.rerun()
            if st.button("üóëÔ∏è Delete"): delete_block_direct(sel_blk, creds, uid); st.cache_data.clear(); del st.session_state['df_full_config']; st.rerun()
        st.divider(); 
        if st.button("üìù Note"): show_note_popup(creds, blks, uid)

    st.subheader(f"Config: {sel_blk}")
    curr_df = st.session_state['df_full_config'][st.session_state['df_full_config'][COL_BLOCK_NAME] == sel_blk].copy().reset_index(drop=True)
    if COL_COPY_FLAG not in curr_df.columns: curr_df.insert(0, COL_COPY_FLAG, False)
    if 'STT' not in curr_df.columns: curr_df.insert(1, 'STT', range(1, len(curr_df)+1))
    
    edt_df = st.data_editor(
        curr_df,
        column_order=[COL_COPY_FLAG, "STT", COL_STATUS, COL_DATA_RANGE, COL_MONTH, COL_SRC_LINK, COL_SRC_SHEET, COL_TGT_LINK, COL_TGT_SHEET, COL_FILTER, COL_HEADER, COL_RESULT, COL_LOG_ROW],
        column_config={
            COL_COPY_FLAG: st.column_config.CheckboxColumn("Copy", width="small", default=False),
            "STT": st.column_config.NumberColumn("STT", width="small", disabled=True),
            COL_STATUS: st.column_config.SelectboxColumn("Tr·∫°ng Th√°i", options=["Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t", "ƒê√£ ch·ªët"], required=True),
            COL_DATA_RANGE: st.column_config.TextColumn("V√πng L·∫•y D·ªØ Li·ªáu", width="small", default="L·∫•y h·∫øt"),
            COL_MONTH: st.column_config.TextColumn("Th√°ng", width="small"),
            COL_SRC_LINK: st.column_config.LinkColumn("Link Ngu·ªìn D·ªØ Li·ªáu", width="medium"), 
            COL_TGT_LINK: st.column_config.LinkColumn("Link ƒê√≠ch D·ªØ li·ªáu", width="medium"),
            COL_FILTER: st.column_config.TextColumn("B·ªô L·ªçc", width="medium"),
            COL_HEADER: st.column_config.CheckboxColumn("C√≥ l·∫•y ti√™u ƒë·ªÅ kh√¥ng?", default=False), 
            COL_RESULT: st.column_config.TextColumn("K·∫øt Qu·∫£", disabled=True),
            COL_LOG_ROW: st.column_config.TextColumn("Log Row", disabled=True),
            COL_BLOCK_NAME: None 
        }, use_container_width=True, num_rows="dynamic", key="edt_v78"
    )

    if edt_df[COL_COPY_FLAG].any():
        nw = []
        for i, r in edt_df.iterrows():
            rc = r.copy(); rc[COL_COPY_FLAG] = False; nw.append(rc)
            if r[COL_COPY_FLAG]: cp = r.copy(); cp[COL_COPY_FLAG] = False; nw.append(cp)
        st.session_state['df_full_config'] = pd.concat([st.session_state['df_full_config'][st.session_state['df_full_config'][COL_BLOCK_NAME] != sel_blk], pd.DataFrame(nw)], ignore_index=True)
        st.rerun()

    st.divider()
    # [V75+V78] N√∫t ch·ª©c nƒÉng n√¢ng c·∫•p
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        if st.button("‚ñ∂Ô∏è RUN BLOCK", type="primary", use_container_width=True):
            save_block_config_to_sheet(edt_df, sel_blk, creds, uid)
            rows = []
            for i, r in edt_df.iterrows():
                if str(r.get(COL_STATUS,'')).strip() == "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t":
                    r_dict = r.to_dict(); r_dict['_index'] = i; rows.append(r_dict)
            if not rows: st.warning("Kh√¥ng c√≥ d√≤ng n√†o ƒë·ªÉ ch·∫°y."); st.stop()
            st_cont = st.status(f"üöÄ ƒêang ch·∫°y {sel_blk}...", expanded=True)
            ok, res, tot = process_pipeline_mixed(rows, uid, sel_blk, st_cont)
            if isinstance(res, dict):
                for i, r in edt_df.iterrows():
                    if i in res: 
                        edt_df.at[i, COL_RESULT] = res[i][0]; edt_df.at[i, COL_LOG_ROW] = res[i][1]
                save_block_config_to_sheet(edt_df, sel_blk, creds, uid)
                st_cont.update(label=f"Done! {tot} rows.", state="complete", expanded=False)
            else: st_cont.update(label="H·ªá th·ªëng b·∫≠n!", state="error", expanded=False)
            st.cache_data.clear(); time.sleep(1); st.rerun()
    
    with c2:
        if st.button("‚è© RUN ALL BLOCKS", use_container_width=True):
            full_df = st.session_state['df_full_config']
            all_blocks = full_df[COL_BLOCK_NAME].unique().tolist()
            if not all_blocks: st.warning("Kh√¥ng c√≥ kh·ªëi n√†o."); st.stop()
            main_status = st.status("üöÄ Kh·ªüi ƒë·ªông chu·ªói x·ª≠ l√Ω...", expanded=True)
            total_processed = 0
            for idx, blk in enumerate(all_blocks):
                main_status.write(f"‚è≥ [{idx+1}/{len(all_blocks)}] ƒêang x·ª≠ l√Ω: **{blk}**...")
                blk_df = full_df[full_df[COL_BLOCK_NAME] == blk].copy().reset_index(drop=True)
                rows_to_run = []
                for i, r in blk_df.iterrows():
                    if str(r.get(COL_STATUS,'')).strip() == "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t":
                        r_dict = r.to_dict(); r_dict['_index'] = i; rows_to_run.append(r_dict)
                if not rows_to_run:
                    main_status.write(f"‚ö™ {blk}: Kh√¥ng c√≥ d√≤ng active. B·ªè qua."); continue
                ok, res, tot = process_pipeline_mixed(rows_to_run, uid, blk, main_status)
                total_processed += tot
                if isinstance(res, dict):
                    has_change = False
                    for i, r in blk_df.iterrows():
                        if i in res:
                            blk_df.at[i, COL_RESULT] = res[i][0]; blk_df.at[i, COL_LOG_ROW] = res[i][1]; has_change = True
                    if has_change:
                        save_block_config_to_sheet(blk_df, blk, creds, uid); main_status.write(f"‚úÖ {blk}: Xong ({tot} d√≤ng).")
                    else: main_status.write(f"‚ö†Ô∏è {blk}: Kh√¥ng c√≥ ph·∫£n h·ªìi.")
                else: main_status.write(f"‚ùå {blk}: L·ªói h·ªá th·ªëng.")
            main_status.update(label=f"üéâ Ho√†n t·∫•t! T·ªïng {total_processed} d√≤ng.", state="complete", expanded=False)
            st.cache_data.clear(); st.toast("Done!", icon="üèÅ"); time.sleep(2); st.rerun()

    with c3:
        if st.button("üîç Qu√©t Quy·ªÅn", use_container_width=True):
            with st.status("Checking...", expanded=True) as st_chk: check_permissions_ui(edt_df.to_dict('records'), creds, st_chk, uid)
    
    with c4:
        if st.button("üíæ Save Config", use_container_width=True): save_block_config_to_sheet(edt_df, sel_blk, creds, uid); st.rerun()

    flush_logs(creds, force=True)
    st.divider(); st.caption("Logs")
    if st.button("Refresh Logs"): st.cache_data.clear()
    logs = fetch_activity_logs(creds, 50)
    if not logs.empty: st.dataframe(logs, use_container_width=True, hide_index=True)

if __name__ == "__main__":
    main_ui()

