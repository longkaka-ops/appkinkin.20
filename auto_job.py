import pandas as pd
import time
import random
import gspread
import json
import os
import pytz
from datetime import datetime
from google.oauth2 import service_account
from gspread_dataframe import get_as_dataframe
from collections import defaultdict

# --- C·∫§U H√åNH (S·ª≠a l·∫°i n·∫øu c·∫ßn, ho·∫∑c d√πng bi·∫øn m√¥i tr∆∞·ªùng) ---
# C√°ch l·∫•y Config: ∆Øu ti√™n l·∫•y t·ª´ Bi·∫øn m√¥i tr∆∞·ªùng (cho Github Actions), 
# n·∫øu kh√¥ng c√≥ th√¨ th·ª≠ l·∫•y t·ª´ file secrets.toml ho·∫∑c ƒëi·ªÅn tr·ª±c ti·∫øp v√†o ƒë√¢y (kh√¥ng khuy·∫øn kh√≠ch ƒëi·ªÅn tr·ª±c ti·∫øp).

SHEET_CONFIG_NAME = "luu_cau_hinh"
SHEET_LOG_NAME = "log_lanthucthi"
SHEET_LOCK_NAME = "sys_lock"

COL_LINK_SRC = "Link file ngu·ªìn"
COL_LABEL_SRC = "Sheet ngu·ªìn"
COL_MONTH_SRC = "Th√°ng"
COL_BLOCK_NAME = "Block_Name"
COL_DATA_RANGE = "V√πng l·∫•y d·ªØ li·ªáu"
DEFAULT_BLOCK_NAME = "Block_Mac_Dinh"

# --- 1. H√ÄM H·ªñ TR·ª¢ X√ÅC TH·ª∞C ---
def get_creds_and_id():
    """
    L·∫•y Credential v√† Sheet ID t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (Environment Variables).
    Setup tr√™n Github Secrets:
    1. GCP_SERVICE_ACCOUNT: Copy to√†n b·ªô n·ªôi dung file JSON v√†o.
    2. HISTORY_SHEET_ID: ID c·ªßa file Google Sheet c·∫•u h√¨nh.
    """
    try:
        # C√°ch 1: L·∫•y t·ª´ Environment Variable (D√πng cho Github Actions/Server)
        creds_json_str = os.environ.get("GCP_SERVICE_ACCOUNT")
        sheet_id = os.environ.get("HISTORY_SHEET_ID")

        # C√°ch 2: (Fallback) N·∫øu ch·∫°y Local m√† ch∆∞a set Env, th·ª≠ ƒë·ªçc t·ª´ file toml (n·∫øu b·∫°n mu·ªën)
        # Ho·∫∑c b·∫°n c√≥ th·ªÉ hard-code t·∫°m th·ªùi ƒë·ªÉ test (nh∆∞ng nh·ªõ x√≥a khi up l√™n git)
        if not creds_json_str:
            # V√≠ d·ª• ƒë·ªçc t·ª´ file local (b·ªè comment n·∫øu c·∫ßn)
            # with open("service_account.json", "r") as f: creds_json_str = f.read()
            # sheet_id = "PASTE_YOUR_SHEET_ID_HERE"
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng GCP_SERVICE_ACCOUNT")
            return None, None

        creds_info = json.loads(creds_json_str)
        if "private_key" in creds_info:
            creds_info["private_key"] = creds_info["private_key"].replace("\\n", "\n")
        
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        creds = service_account.Credentials.from_service_account_info(creds_info, scopes=scopes)
        return creds, sheet_id
    except Exception as e:
        print(f"‚ùå L·ªói Authentication: {e}")
        return None, None

def get_sh_with_retry(creds, sheet_id_or_key):
    gc = gspread.authorize(creds)
    max_retries = 3
    for i in range(max_retries):
        try:
            return gc.open_by_key(sheet_id_or_key)
        except Exception as e:
            if i == max_retries - 1: raise e
            time.sleep((2 ** i) + random.random())
    return None

def extract_id(url):
    if not isinstance(url, str): return None
    if "docs.google.com" in url:
        try: return url.split("/d/")[1].split("/")[0]
        except: return None
    return None

def col_name_to_index(col_name):
    col_name = col_name.upper()
    index = 0
    for char in col_name:
        index = index * 26 + (ord(char) - ord('A')) + 1
    return index - 1

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù DATA (CORE LOGIC) ---
def fetch_data_preserve_columns(row_config, creds):
    link_src = str(row_config.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')).strip()
    source_label = str(row_config.get('T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc', '')).strip()
    month_val = str(row_config.get('Th√°ng', ''))
    data_range_str = str(row_config.get(COL_DATA_RANGE, 'L·∫•y h·∫øt')).strip()
    if not data_range_str or data_range_str.lower() == 'nan': data_range_str = "L·∫•y h·∫øt"
    
    sheet_id = extract_id(link_src)
    if not sheet_id: return None, sheet_id, "Link l·ªói"
    
    df = None
    try:
        sh_source = get_sh_with_retry(creds, sheet_id)
        if source_label:
            try: wks_source = sh_source.worksheet(source_label)
            except: return None, sheet_id, f"‚ùå Kh√¥ng t√¨m th·∫•y sheet: '{source_label}'"
        else: wks_source = sh_source.sheet1
            
        data = wks_source.get_all_values()
        if data and len(data) > 0:
            headers = data[0]
            rows = data[1:]
            if not rows:
                df = pd.DataFrame(columns=headers)
            else:
                df = pd.DataFrame(rows, columns=headers)
            
            if data_range_str != "L·∫•y h·∫øt" and ":" in data_range_str:
                try:
                    start_col_str, end_col_str = data_range_str.split(":")
                    start_idx = col_name_to_index(start_col_str.strip())
                    end_idx = col_name_to_index(end_col_str.strip())
                    if start_idx >= 0 and end_idx >= start_idx:
                        end_idx = min(end_idx, len(df.columns) - 1)
                        df = df.iloc[:, start_idx : end_idx + 1]
                except: pass

            df = df.astype(str).replace(['nan', 'None', '<NA>', 'null'], '')
            status_msg = "Th√†nh c√¥ng"
        else:
            status_msg = "Sheet tr·∫Øng tinh"
            
    except Exception as e:
        return None, sheet_id, f"L·ªói t·∫£i data: {str(e)}"

    if df is not None:
        df[COL_LINK_SRC] = link_src
        df[COL_LABEL_SRC] = source_label
        df[COL_MONTH_SRC] = month_val
        return df, sheet_id, status_msg
    return None, sheet_id, "Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu"

def scan_realtime_row_ranges(target_link, target_sheet_name, creds):
    results = {}
    try:
        target_id = extract_id(target_link)
        if not target_id: return {}
        sh = get_sh_with_retry(creds, target_id)
        real_sheet_name = str(target_sheet_name).strip()
        if not real_sheet_name: real_sheet_name = "Tong_Hop_Data"
        try: wks = sh.worksheet(real_sheet_name)
        except: return {}
        all_data = wks.get_all_values()
        if not all_data: return {}
        headers = all_data[0]
        try: link_col_idx = headers.index(COL_LINK_SRC)
        except ValueError: return {} 
        temp_map = {} 
        for i, row in enumerate(all_data[1:], start=2):
            if len(row) > link_col_idx:
                link_val = row[link_col_idx]
                if link_val:
                    if link_val not in temp_map: temp_map[link_val] = [i, i]
                    else: temp_map[link_val][1] = i 
        for link, (start, end) in temp_map.items():
            results[link] = f"{start} - {end}"
    except: return {}
    return results

def smart_update_safe(tasks_list, target_link, target_sheet_name, creds):
    try:
        target_id = extract_id(target_link)
        if not target_id: return False, "Link ƒë√≠ch l·ªói"
        sh = get_sh_with_retry(creds, target_id)
        real_sheet_name = str(target_sheet_name).strip()
        if not real_sheet_name: real_sheet_name = "Tong_Hop_Data"
        try: wks = sh.worksheet(real_sheet_name)
        except: wks = sh.add_worksheet(title=real_sheet_name, rows=1000, cols=20)
        
        links_to_remove = [t[1] for t in tasks_list if t[1] and len(str(t[1])) > 5]
        existing_headers = []
        try: existing_headers = wks.row_values(1)
        except: pass
        
        if existing_headers and links_to_remove:
            try: 
                link_col_idx = existing_headers.index(COL_LINK_SRC) + 1
                col_values = wks.col_values(link_col_idx)
                rows_to_delete = []
                for i, val in enumerate(col_values):
                    if i > 0 and str(val).strip() in links_to_remove: rows_to_delete.append(i + 1)
                
                if rows_to_delete:
                    rows_to_delete.sort()
                    ranges = []; start = rows_to_delete[0]; end = start
                    for r in rows_to_delete[1:]:
                        if r == end + 1: end = r
                        else: ranges.append((start, end)); start = r; end = r
                    ranges.append((start, end))
                    delete_reqs = []
                    for start, end in reversed(ranges):
                        delete_reqs.append({"deleteDimension": {"range": {"sheetId": wks.id, "dimension": "ROWS", "startIndex": start - 1, "endIndex": end}}})
                    if delete_reqs:
                        sh.batch_update({'requests': delete_reqs})
                        time.sleep(1)
            except ValueError: pass

        if not existing_headers:
            first_df = tasks_list[0][0]
            if first_df is not None and not first_df.empty:
                final_headers = first_df.columns.tolist()
                wks.append_row(final_headers)
                existing_headers = final_headers
            else: return True, "Kh√¥ng c√≥ d·ªØ li·ªáu ngu·ªìn ƒë·ªÉ t·∫°o header"
        else:
            final_headers = existing_headers
            all_new_cols = []
            for t in tasks_list:
                if t[0] is not None: all_new_cols.extend(t[0].columns.tolist())
            seen = set(existing_headers)
            cols_to_add = [x for x in all_new_cols if x not in seen and not seen.add(x)]
            if cols_to_add:
                wks.resize(cols=len(existing_headers) + len(cols_to_add))
                final_headers = existing_headers + cols_to_add
                wks.update(range_name="A1", values=[final_headers])

        data_to_append = []
        for df, src_link in tasks_list:
            if df is not None and not df.empty:
                df_aligned = df.reindex(columns=final_headers, fill_value="")
                data_to_append.extend(df_aligned.values.tolist())

        if data_to_append:
            BATCH_SIZE = 5000
            for i in range(0, len(data_to_append), BATCH_SIZE):
                chunk = data_to_append[i : i + BATCH_SIZE]
                wks.append_rows(chunk)
                time.sleep(1)
            return True, f"Th√†nh c√¥ng (+{len(data_to_append)} d√≤ng)"
        return True, "Th√†nh c√¥ng (Kh√¥ng c√≥ data m·ªõi)"
    except Exception as e: return False, f"L·ªói Ghi: {str(e)}"

# --- 3. SYSTEM LOCK & LOG ---
def get_system_lock(creds, history_id):
    try:
        sh = get_sh_with_retry(creds, history_id)
        try: wks = sh.worksheet(SHEET_LOCK_NAME)
        except: 
            wks = sh.add_worksheet(SHEET_LOCK_NAME, rows=10, cols=5)
            wks.update([["is_locked", "user", "time_start"], ["FALSE", "", ""]])
            return False, "", ""
        val = wks.cell(2, 1).value
        user = wks.cell(2, 2).value
        time_str = wks.cell(2, 3).value
        if val == "TRUE":
            try:
                if (datetime.now() - datetime.strptime(time_str, "%d/%m/%Y %H:%M:%S")).total_seconds() > 1800: return False, "", ""
            except: pass
            return True, user, time_str
        return False, "", ""
    except: return False, "", ""

def set_system_lock(creds, history_id, user_id, lock=True):
    try:
        sh = get_sh_with_retry(creds, history_id)
        try: wks = sh.worksheet(SHEET_LOCK_NAME)
        except: wks = sh.add_worksheet(SHEET_LOCK_NAME, rows=10, cols=5)
        now_str = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        wks.update("A2:C2", [["TRUE", user_id, now_str]] if lock else [["FALSE", "", ""]])
    except: pass

def write_detailed_log(creds, history_id, log_data_list):
    if not log_data_list: return
    try:
        sh = get_sh_with_retry(creds, history_id)
        try: wks = sh.worksheet(SHEET_LOG_NAME)
        except: 
            wks = sh.add_worksheet(SHEET_LOG_NAME, rows=1000, cols=15)
            wks.append_row([
                "Ng√†y & gi·ªù get d·ªØ li·ªáu", "V√πng l·∫•y d·ªØ li·ªáu", "Th√°ng", "Nh√¢n s·ª± get", 
                "Link ngu·ªìn", "Link ƒë√≠ch", "Sheet ƒê√≠ch", "Sheet ngu·ªìn l·∫•y d·ªØ li·ªáu", 
                "Tr·∫°ng Th√°i", "S·ªë D√≤ng ƒê√£ L·∫•y", "D√≤ng d·ªØ li·ªáu c·∫≠p nh·∫≠t", "Ch·∫°y t·ª´ kh·ªëi"
            ])
        wks.append_rows(log_data_list)
    except Exception as e: print(f"L·ªói log: {e}")

# --- 4. PIPELINE ---
def process_pipeline(rows_to_run, user_id, block_name_run, creds, history_id):
    # Lock Check
    is_locked, locking_user, lock_time = get_system_lock(creds, history_id)
    if is_locked and locking_user != user_id and "AutoAll" not in user_id:
        print(f"üîí H·ªá th·ªëng ƒëang b·∫≠n b·ªüi {locking_user}")
        return False, {}, 0
    
    set_system_lock(creds, history_id, user_id, lock=True)
    try:
        grouped_tasks = defaultdict(list)
        total_fetched_rows = 0
        
        for row in rows_to_run:
            raw_t = row.get('Link d·ªØ li·ªáu ƒë√≠ch', '')
            t_link = str(raw_t[0]).strip() if isinstance(raw_t, list) and raw_t else str(raw_t).strip()
            row['Link d·ªØ li·ªáu ƒë√≠ch'] = t_link 
            raw_s = row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')
            s_link = str(raw_s[0]).strip() if isinstance(raw_s, list) and raw_s else str(raw_s).strip()
            row['Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu'] = s_link 
            t_sheet = str(row.get('T√™n sheet d·ªØ li·ªáu ƒë√≠ch', '')).strip()
            if not t_sheet: t_sheet = "Tong_Hop_Data"
            if COL_DATA_RANGE not in row or not row[COL_DATA_RANGE]: row[COL_DATA_RANGE] = "L·∫•y h·∫øt"
            grouped_tasks[(t_link, t_sheet)].append(row)

        global_results_map = {} 
        log_entries = []
        tz_vn = pytz.timezone('Asia/Ho_Chi_Minh')
        time_now = datetime.now(tz_vn).strftime("%d/%m/%Y %H:%M:%S")

        for (target_link, target_sheet), group_rows in grouped_tasks.items():
            if not target_link: continue
            
            tasks_list = []
            for row in group_rows:
                print(f"üì• ƒêang t·∫£i: {row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu')}...")
                df, sid, status = fetch_data_preserve_columns(row, creds)
                src_link = row['Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu']
                
                if df is not None:
                    tasks_list.append((df, src_link))
                    total_fetched_rows += len(df)
                else:
                    global_results_map[src_link] = ("L·ªói t·∫£i/Quy·ªÅn", "")
                    log_entries.append([
                        time_now, str(row.get(COL_DATA_RANGE, 'L·∫•y h·∫øt')), str(row.get('Th√°ng', '')), 
                        user_id, src_link, target_link, target_sheet,
                        row.get('T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc', ''), "L·ªói t·∫£i", "0", "", block_name_run
                    ])

            msg_update = ""
            success_update = True
            if tasks_list:
                print(f"üíæ ƒêang ghi v√†o: {target_link}...")
                success_update, msg_update = smart_update_safe(tasks_list, target_link, target_sheet, creds)
            
            realtime_ranges = scan_realtime_row_ranges(target_link, target_sheet, creds)
            
            for link, rng in realtime_ranges.items():
                if link not in global_results_map: global_results_map[link] = ("C·∫≠p nh·∫≠t l·∫°i", rng)
                else:
                    current_msg = global_results_map[link][0]
                    global_results_map[link] = (current_msg, rng)

            for row in group_rows:
                s_link = row['Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu']
                status_str = "Th√†nh c√¥ng" if success_update else f"L·ªói: {msg_update}"
                final_range = realtime_ranges.get(s_link, "")
                
                if any(t[1] == s_link for t in tasks_list) or (s_link in global_results_map and "L·ªói" in global_results_map[s_link][0]):
                    height = "0"
                    for df, sl in tasks_list:
                        if sl == s_link: height = str(len(df))

                    log_entries.append([
                        time_now, str(row.get(COL_DATA_RANGE, 'L·∫•y h·∫øt')), str(row.get('Th√°ng', '')),
                        user_id, s_link, target_link, target_sheet,
                        row.get('T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc', ''), 
                        status_str, height, final_range, block_name_run
                    ])
                    global_results_map[s_link] = (status_str, final_range)
        
        write_detailed_log(creds, history_id, log_entries)
        return True, global_results_map, total_fetched_rows
    finally:
        set_system_lock(creds, history_id, user_id, lock=False)

def verify_access_fast(url, creds):
    sheet_id = extract_id(url)
    if not sheet_id: return False, "Link l·ªói"
    try:
        get_sh_with_retry(creds, sheet_id)
        return True, "OK"
    except Exception as e: return False, f"L·ªói: {e}"

def check_permissions_strict(rows_to_run, creds):
    checked_links = {} 
    for row in rows_to_run:
        # Ngu·ªìn
        link_src = str(row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')).strip()
        if "docs.google.com" in link_src:
            if link_src not in checked_links: checked_links[link_src] = verify_access_fast(link_src, creds)
            if not checked_links[link_src][0]: return False
        # ƒê√≠ch
        link_tgt = str(row.get('Link d·ªØ li·ªáu ƒë√≠ch', '')).strip()
        if "docs.google.com" in link_tgt:
            if link_tgt not in checked_links: checked_links[link_tgt] = verify_access_fast(link_tgt, creds)
            if not checked_links[link_tgt][0]: return False
    return True

# --- MAIN RUNNER ---
def main():
    print("üöÄ B·∫ÆT ƒê·∫¶U CH·∫†Y AUTO JOB...")
    creds, history_id = get_creds_and_id()
    if not creds or not history_id:
        print("‚ùå Thi·∫øu Credential ho·∫∑c ID Sheet Config. D·ª´ng.")
        return

    try:
        # 1. T·∫£i Config
        print("üì• ƒêang ƒë·ªçc c·∫•u h√¨nh...")
        sh_config = get_sh_with_retry(creds, history_id)
        wks_config = sh_config.worksheet(SHEET_CONFIG_NAME)
        df_full = get_as_dataframe(wks_config, evaluate_formulas=True, dtype=str)
        df_full = df_full.dropna(how='all')
        
        # Chu·∫©n h√≥a c·ªôt
        required_cols = ['Tr·∫°ng th√°i', COL_DATA_RANGE, 'Th√°ng', 'Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', 'Link d·ªØ li·ªáu ƒë√≠ch', 'T√™n sheet d·ªØ li·ªáu ƒë√≠ch', 'T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc', 'K·∫øt qu·∫£', 'D√≤ng d·ªØ li·ªáu', COL_BLOCK_NAME]
        for c in required_cols:
            if c not in df_full.columns: df_full[c] = ""
        df_full[COL_BLOCK_NAME] = df_full[COL_BLOCK_NAME].replace('', DEFAULT_BLOCK_NAME).fillna(DEFAULT_BLOCK_NAME)
        df_full[COL_DATA_RANGE] = df_full[COL_DATA_RANGE].replace('', 'L·∫•y h·∫øt').fillna('L·∫•y h·∫øt')
        if 'Tr·∫°ng th√°i' in df_full.columns:
            df_full['Tr·∫°ng th√°i'] = df_full['Tr·∫°ng th√°i'].apply(lambda x: "ƒê√£ ch·ªët" if str(x).strip() in ["ƒê√£ ch·ªët", "ƒê√£ c·∫≠p nh·∫≠t", "TRUE"] else "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t")

        all_blocks = df_full[COL_BLOCK_NAME].unique()
        total_all_rows = 0
        user_id_run = "Auto_Bot_Github"

        # 2. Duy·ªát t·ª´ng Block
        for blk in all_blocks:
            print(f"‚è≥ Ki·ªÉm tra kh·ªëi: {blk}...")
            block_mask = (df_full[COL_BLOCK_NAME] == blk) & (df_full['Tr·∫°ng th√°i'] == "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t")
            rows_blk = df_full[block_mask].to_dict('records')

            if rows_blk:
                # Check quy·ªÅn
                if not check_permissions_strict(rows_blk, creds):
                    print(f"‚ùå Kh·ªëi {blk} b·ªã b·ªè qua do l·ªói quy·ªÅn.")
                    continue
                
                # Ch·∫°y Pipeline
                _, results_map, rows_count = process_pipeline(rows_blk, user_id_run, blk, creds, history_id)
                total_all_rows += rows_count
                
                # C·∫≠p nh·∫≠t k·∫øt qu·∫£ v√†o DataFrame
                if results_map:
                    for idx, row in df_full[block_mask].iterrows():
                        s_link = str(row['Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu']).strip()
                        if s_link in results_map:
                            msg, rng = results_map[s_link]
                            df_full.at[idx, 'K·∫øt qu·∫£'] = msg
                            df_full.at[idx, 'D√≤ng d·ªØ li·ªáu'] = rng
                print(f"‚úÖ Xong kh·ªëi {blk} (+{rows_count} d√≤ng).")
            else:
                print(f"‚ö™ Kh·ªëi {blk} kh√¥ng c√≥ d·ªØ li·ªáu c·∫ßn ch·∫°y.")

        # 3. L∆∞u to√†n b·ªô Config xu·ªëng Sheet
        print("üíæ ƒêang l∆∞u k·∫øt qu·∫£ c·∫≠p nh·∫≠t...")
        target_cols = [
            COL_BLOCK_NAME, 'Tr·∫°ng th√°i', COL_DATA_RANGE, 'Th√°ng', 
            'Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', 'Link d·ªØ li·ªáu ƒë√≠ch', 'T√™n sheet d·ªØ li·ªáu ƒë√≠ch', 
            'D√≤ng d·ªØ li·ªáu', 'K·∫øt qu·∫£', 'T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc'
        ]
        df_full = df_full.astype(str).replace(['nan', 'None', '<NA>'], '')
        for c in target_cols:
            if c not in df_full.columns: df_full[c] = ""
        df_full = df_full[target_cols]
        
        wks_config.clear()
        wks_config.update([df_full.columns.tolist()] + df_full.values.tolist())
        print(f"üèÅ HO√ÄN T·∫§T! T·ªïng {total_all_rows} d√≤ng.")

    except Exception as e:
        print(f"‚ùå L·ªñI FATAL: {e}")

if __name__ == "__main__":
    main()
